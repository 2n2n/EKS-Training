# Kubernetes Concepts: Container Orchestration

**Estimated Reading Time: 45 minutes**

---

## ğŸ¯ What is Kubernetes?

**Kubernetes** (K8s) is a container orchestration platform. It manages Docker containers across multiple servers.

**Simple analogy:** If Docker is like shipping containers, Kubernetes is the port authority that manages thousands of containers across many ships and docks.

---

## ğŸ¤” Why Do You Need Kubernetes?

### Docker Alone: Good for One Server

```bash
# You can manage containers on one server:
docker run -d app1
docker run -d app2
docker run -d app3

# But what about:
# - 10 servers with 100 containers?
# - Auto-restart if container crashes?
# - Load balancing across containers?
# - Rolling updates with zero downtime?
# - Auto-scaling based on load?

Docker doesn't solve these!
```

### Kubernetes: Manages Many Servers

```
Kubernetes Cluster:
â”œâ”€â”€ Server 1
â”‚   â”œâ”€â”€ Container A
â”‚   â””â”€â”€ Container B
â”œâ”€â”€ Server 2
â”‚   â”œâ”€â”€ Container C
â”‚   â””â”€â”€ Container D
â””â”€â”€ Server 3
    â”œâ”€â”€ Container E
    â””â”€â”€ Container F

Kubernetes:
âœ… Decides which server runs which container
âœ… Restarts crashed containers
âœ… Load balances traffic
âœ… Rolls out updates
âœ… Scales automatically
```

---

## ğŸ—ï¸ Kubernetes Architecture

### High-Level View

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Kubernetes Cluster                    â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     Control Plane (The Brain)             â”‚  â”‚
â”‚  â”‚  - API Server (talks to you)              â”‚  â”‚
â”‚  â”‚  - Scheduler (decides placement)          â”‚  â”‚
â”‚  â”‚  - Controller Manager (maintains state)   â”‚  â”‚
â”‚  â”‚  - etcd (database)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                            â”‚
â”‚                     â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        Worker Nodes (The Muscle)         â”‚   â”‚
â”‚  â”‚                                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ Node 1 â”‚  â”‚ Node 2 â”‚  â”‚ Node 3 â”‚    â”‚   â”‚
â”‚  â”‚  â”‚        â”‚  â”‚        â”‚  â”‚        â”‚    â”‚   â”‚
â”‚  â”‚  â”‚ Pods   â”‚  â”‚ Pods   â”‚  â”‚ Pods   â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Traditional equivalent:**

```
Traditional:              Kubernetes:
Your commands       â†’     Control Plane
Your servers        â†’     Worker Nodes
Your applications   â†’     Pods
```

---

## ğŸ§© Core Kubernetes Objects

### 1. Pod - The Smallest Unit

**What is it?**
A Pod is a wrapper around one or more containers.

```
Pod = 1 or more containers that run together

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Pod           â”‚
â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Container 1 â”‚  â”‚  â† Usually just one
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚
â”‚  (Sometimes more)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Container 2 â”‚  â”‚  â† Helper/sidecar
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Pod gets:
- Unique IP address
- Shared storage
- Shared network
```

**Traditional equivalent:**

```
Pod â‰ˆ Application instance

Traditional:          Kubernetes:
Node.js process  â†’    Pod with Node.js container
nginx process    â†’    Pod with nginx container
```

**Example Pod YAML:**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
spec:
  containers:
  - name: myapp
    image: myapp:v1
    ports:
    - containerPort: 3000
```

**Life of a Pod:**

```
1. Pending â†’ Scheduled to a node
2. Running â†’ Container(s) running
3. Succeeded/Failed â†’ Completed
4. Pods are disposable!

Pod crashes? Create new one.
Pod's node fails? Create new one elsewhere.
```

### 2. Deployment - Manages Pods

**What is it?**
Deployment manages multiple identical Pods and handles updates.

```
Deployment: "I want 3 replicas of myapp:v1"

                Deployment
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚
     Pod 1       Pod 2       Pod 3
    myapp:v1    myapp:v1    myapp:v1

If Pod 2 crashes:
- Kubernetes detects
- Creates new Pod 2
- Always maintains 3 replicas
```

**Traditional equivalent:**

```
Traditional:                 Kubernetes Deployment:
pm2 start server.js -i 3  â†’ 3 Pod replicas
pm2 restart               â†’ Rolling update
Auto-restart on crash     â†’ Self-healing pods
```

**Example Deployment YAML:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 3  # "I want 3 copies"
  selector:
    matchLabels:
      app: myapp
  template:  # Pod template
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myapp:v1
        ports:
        - containerPort: 3000
```

**Rolling Updates:**

```
Current: 3 Pods running v1
Update to: v2

Kubernetes automatically:
1. Creates 1 Pod with v2
2. Waits for it to be ready
3. Deletes 1 Pod with v1
4. Repeat until all Pods are v2

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ v1      â”‚   â”‚ v1      â”‚   â”‚ v1      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ v1      â”‚   â”‚ v1      â”‚   â”‚ v1      â”‚   â”‚ v2      â”‚ â† New
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ v1      â”‚   â”‚ v1      â”‚   â”‚ v2      â”‚ â† Old removed
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Continue until all v2...
Zero downtime! âœ…
```

### 3. Service - Networking & Load Balancing

**What is it?**
Service provides a stable way to access Pods (which have changing IPs).

**The Problem:**

```
Pods are ephemeral:
- Pod 1: IP 10.0.1.5  â† Crashes
- Pod 1 (new): IP 10.0.1.8  â† Different IP!

How do other Pods find your app?
IPs keep changing!
```

**The Solution: Service**

```
Service: Stable IP/DNS name
    â”‚
    â”œâ”€â†’ Routes to Pod 1 (10.0.1.5)
    â”œâ”€â†’ Routes to Pod 2 (10.0.1.7)
    â””â”€â†’ Routes to Pod 3 (10.0.1.9)

Access "myapp-service" â†’ Load balanced to any Pod
Service IP never changes!
```

**Traditional equivalent:**

```
Traditional:               Kubernetes Service:
nginx load balancer   â†’    Service with ClusterIP
HAProxy               â†’    Service
Internal DNS          â†’    Service discovery
```

**Service Types:**

```yaml
# 1. ClusterIP (default) - Internal only
kind: Service
spec:
  type: ClusterIP  # Only accessible inside cluster
  ports:
  - port: 80
    targetPort: 3000

# 2. NodePort - External access via node IP
kind: Service
spec:
  type: NodePort  # Accessible from outside
  ports:
  - port: 80
    targetPort: 3000
    nodePort: 30080  # Access via node-ip:30080

# 3. LoadBalancer - Cloud load balancer
kind: Service
spec:
  type: LoadBalancer  # Creates AWS/GCP load balancer
  ports:
  - port: 80
    targetPort: 3000
```

**Example Service YAML:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  selector:
    app: myapp  # Routes to Pods with this label
  ports:
  - port: 80        # Service port
    targetPort: 3000  # Container port
  type: NodePort
```

### 4. ConfigMap - Configuration Data

**What is it?**
Store configuration data (non-sensitive) separately from code.

```
Without ConfigMap:
- Hard-code values in container
- Rebuild image for every config change
- Different images for dev/staging/prod

With ConfigMap:
- Store config in Kubernetes
- Same image everywhere
- Change config without rebuilding
```

**Traditional equivalent:**

```
Traditional:           Kubernetes:
.env file         â†’    ConfigMap
config.json       â†’    ConfigMap
Environment vars  â†’    ConfigMap
```

**Example ConfigMap:**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database_host: "postgres.default.svc.cluster.local"
  api_url: "https://api.example.com"
  log_level: "info"
```

**Using in Pod:**

```yaml
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: myapp
    image: myapp:v1
    envFrom:
    - configMapRef:
        name: app-config
    # Container sees DATABASE_HOST, API_URL, LOG_LEVEL
```

### 5. Secret - Sensitive Data

**What is it?**
Like ConfigMap but for sensitive data (passwords, tokens).

```
ConfigMap: Public config (URLs, settings)
Secret: Private config (passwords, API keys)
```

**Example Secret:**

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  db_password: bXlwYXNzd29yZA==  # base64 encoded
  api_key: c2VjcmV0a2V5MTIz
```

**Using in Pod:**

```yaml
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: myapp
    image: myapp:v1
    env:
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: db_password
```

### 6. Namespace - Logical Separation

**What is it?**
Namespaces separate resources within same cluster.

```
Cluster
â”œâ”€â”€ Namespace: development
â”‚   â”œâ”€â”€ Deployment: frontend
â”‚   â””â”€â”€ Service: backend
â”œâ”€â”€ Namespace: staging
â”‚   â”œâ”€â”€ Deployment: frontend
â”‚   â””â”€â”€ Service: backend
â””â”€â”€ Namespace: production
    â”œâ”€â”€ Deployment: frontend
    â””â”€â”€ Service: backend

Same names, different namespaces
Isolated from each other
```

**Traditional equivalent:**

```
Traditional:          Kubernetes:
Separate servers  â†’   Namespaces
/var/www/dev      â†’   dev namespace
/var/www/prod     â†’   prod namespace
```

**Default Namespaces:**

```bash
# Kubernetes creates these:
default          # Your stuff goes here by default
kube-system      # Kubernetes system components
kube-public      # Public resources
kube-node-lease  # Node heartbeat data
```

---

## ğŸ­ How It All Works Together

### Complete Example: Todo App

```yaml
# 1. ConfigMap - Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: todo-config
data:
  api_url: "http://backend-service:3000"

---
# 2. Secret - Sensitive data
apiVersion: v1
kind: Secret
metadata:
  name: todo-secrets
type: Opaque
data:
  jwt_secret: c2VjcmV0MTIz

---
# 3. Deployment - Backend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: todo-backend:v1
        ports:
        - containerPort: 3000
        envFrom:
        - secretRef:
            name: todo-secrets

---
# 4. Service - Backend
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  selector:
    app: backend
  ports:
  - port: 3000
    targetPort: 3000
  type: ClusterIP  # Internal only

---
# 5. Deployment - Frontend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: todo-frontend:v1
        ports:
        - containerPort: 80
        envFrom:
        - configMapRef:
            name: todo-config

---
# 6. Service - Frontend
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
spec:
  selector:
    app: frontend
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30080
  type: NodePort  # External access
```

**What happens:**

```
1. User visits: http://node-ip:30080
   â†“
2. NodePort service routes to frontend Pod
   â†“
3. Frontend calls backend via "backend-service:3000"
   â†“
4. Service load-balances to backend Pod
   â†“
5. Backend processes request
   â†“
6. Response flows back to user
```

---

## ğŸ”„ Kubernetes Control Loop

### Declarative vs Imperative

**Imperative (Traditional):**

```bash
# You tell system HOW to do things:
ssh server1
docker run myapp
ssh server2
docker run myapp
# Step by step commands
```

**Declarative (Kubernetes):**

```yaml
# You tell system WHAT you want:
spec:
  replicas: 3
# Kubernetes figures out HOW
```

### The Control Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. You declare desired state:     â”‚
â”‚     "I want 3 Pods running"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Kubernetes checks actual state: â”‚
â”‚     "Currently 2 Pods running"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Kubernetes reconciles:          â”‚
â”‚     "I need to create 1 more Pod"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Kubernetes creates Pod          â”‚
â”‚     "Now 3 Pods running âœ…"          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        (Continuously monitors)
```

**This happens automatically, continuously, forever!**

---

## ğŸ› ï¸ kubectl - The Kubernetes CLI

### Basic Commands

```bash
# View resources
kubectl get pods               # List pods
kubectl get deployments        # List deployments
kubectl get services           # List services
kubectl get all                # List everything

# Describe (detailed info)
kubectl describe pod myapp-pod
kubectl describe deployment myapp

# Create resources
kubectl create -f deployment.yaml
kubectl apply -f deployment.yaml  # Preferred (updates existing)

# Delete resources
kubectl delete pod myapp-pod
kubectl delete deployment myapp

# View logs
kubectl logs myapp-pod
kubectl logs -f myapp-pod  # Follow logs

# Execute commands
kubectl exec -it myapp-pod -- bash  # Like docker exec

# Scale deployment
kubectl scale deployment myapp --replicas=5
```

**Traditional equivalent:**

```
Traditional:          kubectl:
ssh commands     â†’    kubectl exec
service logs     â†’    kubectl logs
ps aux           â†’    kubectl get pods
service restart  â†’    kubectl rollout restart
```

---

## ğŸ“Š Kubernetes vs Traditional Comparison

| Task | Traditional | Kubernetes |
|------|-------------|------------|
| **Deploy app** | SSH + manual steps | `kubectl apply` |
| **Scale up** | Set up new servers | `kubectl scale` |
| **Update app** | SSH to each server | Rolling update |
| **Restart crashed app** | Manual | Automatic |
| **Load balance** | Configure nginx/HAProxy | Built-in Service |
| **Configuration** | Edit files on servers | ConfigMap/Secret |
| **Service discovery** | Manual DNS/hosts file | Automatic |
| **Health checks** | External monitoring | Built-in liveness probes |
| **Rollback** | Manual restore | `kubectl rollout undo` |

---

## âœ… Key Takeaways

### Kubernetes Provides:
- âœ… Container orchestration across many servers
- âœ… Self-healing (auto-restart)
- âœ… Auto-scaling
- âœ… Load balancing
- âœ… Rolling updates
- âœ… Service discovery
- âœ… Configuration management

### Core Concepts:
- **Pod**: Smallest unit (1+ containers)
- **Deployment**: Manages Pods, handles updates
- **Service**: Stable networking, load balancing
- **ConfigMap**: Non-sensitive configuration
- **Secret**: Sensitive data
- **Namespace**: Logical separation

### Philosophy:
- **Declarative**: Describe what you want
- **Self-healing**: Maintains desired state
- **Immutable**: Replace, don't modify
- **Scalable**: Designed for many servers

---

## ğŸš€ Next Steps

You now understand core Kubernetes concepts!

**Next:** [04-AWS-Fundamentals.md](04-AWS-Fundamentals.md) - Learn the AWS services we'll use for EKS!

---

**Remember:** Kubernetes automates what you've been doing manually. Same concepts, automated execution! ğŸ¤–

